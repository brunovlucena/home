
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: prometheus-operator
  namespace: prometheus
spec:
  interval: 5m
  timeout: 20m
  chart:
    spec:
      chart: kube-prometheus-stack
      version: 77.10.0
      sourceRef:
        kind: HelmRepository
        name: prometheus-community
        namespace: flux-system
  values:
    prometheus:
      prometheusSpec:
        retention: 7d
        additionalArgs:
          - name: "enable-feature"
            value: "native-histograms"
        storageSpec:
          volumeClaimTemplate:
            spec:
              storageClassName: standard
              accessModes: ["ReadWriteOnce"]
              resources:
                requests:
                  storage: 10Gi
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 1Gi
        nodeSelector:
          role: mcp-servers
        tolerations:
          - key: "observability"
            operator: Equal
            value: "true"
            effect: NoSchedule
        containers:
          - name: prometheus
            ports:
              - name: web
                containerPort: 30090
                protocol: TCP
      service:
        type: NodePort
        ports:
          - name: web
            port: 9090
            targetPort: 30090
            nodePort: 30090
    grafana:
      adminPassword: adminbubs # TODO: Sealed Secrets
      initChownData:
        enabled: false
      containers:
        - name: grafana
          ports:
            - name: http
              containerPort: 3000
              protocol: TCP
            - name: additional
              containerPort: 30080
              protocol: TCP
      resources:
        requests:
          cpu: 100m
          memory: 128Mi
        limits:
          cpu: 500m
          memory: 512Mi
      nodeSelector:
        role: mcp-servers
      tolerations:
        - key: "observability"
          operator: Equal
          value: "true"
          effect: NoSchedule
      persistence:
        enabled: true
        type: pvc
        storageClassName: standard
        size: 10Gi
        accessModes:
          - ReadWriteOnce
        annotations: {}
        finalizers:
          - kubernetes.io/pvc-protection
        mountPath: /var/lib/grafana
        subPath: ""
        existingClaim: ""
        readOnly: false
      service:
        type: ClusterIP
      ingress:
        enabled: false
        ingressClassName: istio # cloudflare and flagger
        hosts:
          - grafana.lucena.cloud
        path: /
        pathType: Prefix
      plugins:
        - grafana-strava-datasource
        - grafana-llm-app
      grafana.ini:
        unified_alerting:
          enabled: true
        provisioning:
          contactpoints: true
          notification_policies: true
      sidecar:
        datasources:
          enabled: true
          label: grafana_datasource
          labelValue: "1"
        dashboards:
          enabled: true
          label: grafana_dashboard
          labelValue: "1"
        contactpoints:
          enabled: true
          label: grafana_contact_points
          labelValue: "true"
        notification_policies:
          enabled: true
          label: grafana_notification_policies
          labelValue: "true"
      env:
        STRAVA_CLIENT_ID:
          valueFrom:
            secretKeyRef:
              name: strava-secrets
              key: client-id
        STRAVA_CLIENT_SECRET:
          valueFrom:
            secretKeyRef:
              name: strava-secrets
              key: client-secret
        STRAVA_ACCESS_TOKEN:
          valueFrom:
            secretKeyRef:
              name: strava-secrets
              key: access-token
        STRAVA_REFRESH_TOKEN:
          valueFrom:
            secretKeyRef:
              name: strava-secrets
              key: refresh-token
        STRAVA_EXPIRES_AT:
          valueFrom:
            secretKeyRef:
              name: strava-secrets
              key: expires-at
        GRAFANA_LLM_OLLAMA_URL:
          value: "http://192.168.0.12:11434"
        GRAFANA_LLM_OLLAMA_MODEL:
          value: "gemma3n:e4b"
        PAGERDUTY_SERVICE_KEY:
          valueFrom:
            secretKeyRef:
              name: pagerduty-secrets
              key: PAGERDUTY_SERVICE_KEY
        SLACK_WEBHOOK_URL:
          valueFrom:
            secretKeyRef:
              name: pagerduty-secrets
              key: SLACK_WEBHOOK_URL
      datasources:
        datasources.yaml:
          apiVersion: 1
          datasources:
            - name: Strava
              type: grafana-strava-datasource
              access: proxy
              url: https://www.strava.com
              isDefault: false
              editable: true
              jsonData:
                clientId: "${STRAVA_CLIENT_ID}"
                clientSecret: "${STRAVA_CLIENT_SECRET}"
                accessToken: "${STRAVA_ACCESS_TOKEN}"
                refreshToken: "${STRAVA_REFRESH_TOKEN}"
                expiresAt: "${STRAVA_EXPIRES_AT}"
            - name: Loki
              uid: loki
              type: loki
              access: proxy
              url: http://loki-read.loki:3100
              isDefault: false
              editable: true
              jsonData:
                maxLines: 1000
                timeout: 60
                httpHeaderName1: "X-Scope-OrgID"
              secureJsonData:
                httpHeaderValue1: "fake"
            - name: Tempo
              uid: tempo
              type: tempo
              access: proxy
              url: http://tempo-query-frontend.tempo:3100
              isDefault: false
              editable: true
              jsonData:
                tracesToLogs:
                  datasourceUid: 'loki'
                  tags: ['job', 'instance', 'pod', 'namespace']
                  mappedTags: [{ key: 'service.name', value: 'service' }]
                  mapTagNamesEnabled: false
                  spanStartTimeShift: '-1h'
                  spanEndTimeShift: '1h'
                  filterByTraceID: false
                  filterBySpanID: false
                tracesToMetrics:
                  datasourceUid: 'prometheus'
                  tags: [{ key: 'service.name', value: 'service' }, { key: 'job' }]
                  queries:
                    - name: 'Sample query'
                      query: 'sum(rate(traces_spanmetrics_latency_bucket{$$__tags}[5m]))'
                serviceMap:
                  datasourceUid: 'prometheus'
                search:
                  hide: false
                nodeGraph:
                  enabled: true
    alertmanager:
      enabled: true
      replicas: 1
      alertmanagerConfigSelector:
        matchLabels:
          app: kube-prometheus-stack-alertmanager
      alertmanagerSpec:
        configSecret: alertmanager-prometheus-operator-kube-p-alertmanager
        secrets:
        - pagerduty-secrets
        storage:
          volumeClaimTemplate:
            spec:
              storageClassName: standard
              accessModes: ["ReadWriteOnce"]
              resources:
                requests:
                  storage: 10Gi
        config:
          global:
            resolve_timeout: 5m
          route:
            group_by: ['alertname']
            group_wait: 10s
            group_interval: 10s
            repeat_interval: 1h
            receiver: 'slack-default'
            routes:
            - match:
                severity: critical
              receiver: 'pagerduty-critical'
            - match:
                severity: warning
              receiver: 'slack-warning'
            - match:
                severity: info
              receiver: 'slack-info'
          receivers:
          - name: 'pagerduty-critical'
            pagerduty_configs:
            - service_key: '${PAGERDUTY_SERVICE_KEY}'
              description: '{{ .GroupLabels.alertname }}'
              details:
                summary: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
                severity: '{{ .GroupLabels.severity }}'
                namespace: '{{ .GroupLabels.namespace }}'
                instance: '{{ .GroupLabels.instance }}'
              client: 'Alertmanager'
              client_url: '{{ .ExternalURL }}'
              severity: 'critical'
              component: '{{ .GroupLabels.alertname }}'
              group: '{{ .GroupLabels.alertname }}'
              class: '{{ .GroupLabels.alertname }}'
          - name: 'slack-default'
            slack_configs:
            - api_url: '${SLACK_WEBHOOK_URL}'
              channel: '#jamie-sre-chatbot'
              title: 'Alert: {{ .GroupLabels.alertname }}'
              text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
              send_resolved: true
          - name: 'slack-warning'
            slack_configs:
            - api_url: '${SLACK_WEBHOOK_URL}'
              channel: '#jamie-sre-chatbot'
              title: '⚠️ Warning: {{ .GroupLabels.alertname }}'
              text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
              send_resolved: true
          - name: 'slack-info'
            slack_configs:
            - api_url: '${SLACK_WEBHOOK_URL}'
              channel: '#jamie-sre-chatbot'
              title: 'ℹ️ Info: {{ .GroupLabels.alertname }}'
              text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
              send_resolved: true
          inhibit_rules:
          - target_match:
              severity: warning
            source_match:
              severity: critical
            equal: ['namespace', 'alertname']
          - target_match:
              severity: info
            source_match:
              severity: warning
            equal: ['namespace', 'alertname']
        env:
        - name: PAGERDUTY_SERVICE_KEY
          valueFrom:
            secretKeyRef:
              name: pagerduty-secrets
              key: PAGERDUTY_SERVICE_KEY
        - name: SLACK_WEBHOOK_URL
          valueFrom:
            secretKeyRef:
              name: pagerduty-secrets
              key: SLACK_WEBHOOK_URL